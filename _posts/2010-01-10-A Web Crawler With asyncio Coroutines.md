---
layout: post
title:  【翻译】 A Web Crawler With asyncio Coroutines
excerpt: ''
categories: 网络
tags: Python
---

## 概述

传统的计算机科学常强调有效的算法，来尽快地完成计算。但许多网络程序耗时不在计算上，而在保持大量缓慢或偶发的连接上。这些程序提出了非常不同的挑战：有效地等待大量的网络事件。解决这个问题的一个现代方法是异步I/O，或 `async`。

本文介绍一个简单的网络爬虫。网络爬虫等待许多响应，但只进行少量计算，是典型的的异步应用。一次抓取的页面越多则完成地越快。如果为每个进行中的请求分配一个线程，则随着并发请求数的增加，在耗尽套接字之前，内存或其他与线程相关的资源将被耗尽。通过使用异步I/O，可避免了对线程的需求。

我们分三个阶段介绍该示例。 首先，我们展示一个异步事件循环，并简述一个使用事件循环和回调的爬虫：它非常有效，但将其扩展到更复杂的问题时会导致难以处理的面条式代码。因此，第二阶段我们将展示 Python 协程既高效又可扩展。我们使用生成器函数在 Python 中实现简单的协程。 在第三阶段，我们使用 Python 标准的 `asyncio` 库中功能齐全的协程，并使用异步队列进行协调。

## 任务

网络爬虫应用寻找并下载网站的所有页面，可能对它们进行存储或索引。程序从根路径开始获取每个页面，解析页面以查找不可见的页面链接，并将它们添加到队列中。当页面没有不可见链接并且队列为空时，程序将停止。

同时下载多个页面可加速爬取过程。当爬虫程序找到新的链接时，在不同的套接字上同时对这些页面启动抓取操作。解析到达的响应，并将新链接添加到队列中。并发数太多会降低性能，可能造成收益递减的情况，因此可限制并发请求数量，将其余链接留在队列中，直到完成当前的请求。

## 传统方法

如何让爬虫并发？传统方法是创建一个线程池。每个线程通过一个套接字下载一个页面。例如要从 xkcd.com 下载页面：

```python
def fetch(url):
    sock = socket.socket()
    sock.connect(('xkcd.com', 80))
    request = 'GET {} HTTP/1.0\r\nHost: xkcd.com\r\n\r\n'.format(url)
    sock.send(request.encode('ascii'))
    response = b''
    chunk = sock.recv(4096)
    while chunk:
        response += chunk
        chunk = sock.recv(4096)

    # Page is now downloaded.
    links = parse_links(response)
    q.add(links)
```

默认情况下，套接字操作处于阻塞状态：当线程调用诸如 `connect` 或 `recv` 之类的方法时，它将暂停直到操作完成。因此，要一次下载多个页面，我们需要多个线程。复杂的应用程序通过将空闲线程保留在线程池中，然后将其检出重新用于后续任务，以此摊销线程创建的成本；它与连接池中的套接字相同。

然而，线程成本很高，并且操作系统对进程、用户或机器可能具有的线程数施加各种硬性限制。在 Jesse 系统上，Python 线程消耗大约 50KB 内存，启动数万个线程会导致失败。如果我们在并发套接字上进行成千上万的同时操作，那么在套接字用完之前，线程就用完了。每个线程的开销或系统对线程的限制是瓶颈。

Dan Kegel 在其著名的 "C10K问题" 论文中，概述了多线程对 I/O 并发的局限性。他开头写道：
>是时候让 Web 服务器同时处理一万个客户端了，不是吗？ 今非昔比，如今网络世界太大了。

Kegel 于 1999 年创造了 "C10K" 一词。如今，一万个连接听起来很精确，但问题只有量的变化，而没有质的变化。 当时对于C10K 问题，在每个连接中创建线程是不切实际的。现在，上限提高了几个数量级。确实，基于多线程的网络爬虫可以正常工作，但是对于具有数十万个连接的超大型应用程序，上限仍然存在：这个限制是，大多数系统虽然还可以创建套接字，但线程用完了。我们该如何解决该问题呢？

## Async

异步 I/O 框架使用非阻塞套接字在单个线程上执行并发操作。在异步爬虫中，开始连接到服务器之前将套接字设置为非阻塞：

```python
sock = socket.socket()
sock.setblocking(False)
try:
    sock.connect(('xkcd.com', 80))
except BlockingIOError:
    pass
```

烦人的是，即使非阻塞套接字正常运行，它也会从 `connect` 引发异常。此异常复制了底层 C 函数中令人厌恶的行为，该函数将`errno` 设置为 `EINPROGRESS` 以告知它已经开始。

现在，爬虫程序需要一种方法来知道何时建立连接，以便它可以发送 HTTP 请求。 可以简单在循环中进行尝试：

```python
request = 'GET {} HTTP/1.0\r\nHost: xkcd.com\r\n\r\n'.format(url)
encoded = request.encode('ascii')

while True:
    try:
        sock.send(encoded)
        break  # Done.
    except OSError as e:
        pass

print('sent')
```

这种方法不仅成本高，而且不能有效地等待多个套接字上的事件。在远古时代，BSD Unix 解决此问题的方法是使用 C 函数 `select`，该函数在非阻塞套接字或其中的一小部分套接字上等待事件发生。 如今，对具有大量连接的互联网应用程序的需求，导致了一些程序取代了 `select`, 例如 `poll` BSD 上的 `kqueue` 和 Linux 上的 `epoll`。 这些 API 与 select 类似，但是在处理大量连接时表现更佳。

Python 3.4 的 `DefaultSelector` 使用系统上可用的最佳的类 `select` 函数。为注册有关网络 I/O 的通知，我们创建一个非阻塞套接字，并使用默认选择器注册它：

```python
from selectors import DefaultSelector, EVENT_WRITE

selector = DefaultSelector()

sock = socket.socket()
sock.setblocking(False)
try:
    sock.connect(('xkcd.com', 80))
except BlockingIOError:
    pass

def connected():
    selector.unregister(sock.fileno())
    print('connected!')

selector.register(sock.fileno(), EVENT_WRITE, connected)
```

我们忽略了虚假错误，并调用 `selector.register`，传入套接字的文件描述符和一个常量，该常量表示正在等待的事件。为了在建立连接时得到通知，我们传递 `EVENT_WRITE` ：也就是说，我们想知道套接字何时是“可写的”。 我们还会传递一个 Python 函数 `connected`，以在该事件发生时运行。这种功能称为回调。

当选择器接收到 I/O 通知时，将对其进行循环处理：

```python
def loop():
    while True:
        events = selector.select()
        for event_key, event_mask in events:
            callback = event_key.data
            callback()
```

`connected` 的回调存储为 `event_key.data`，一旦连接了非阻塞套接字，便检索并执行该回调。

与上面的快速旋转循环不同，此处对 `select` 的调用会暂停，以等待下一个 I/O 事件。然后循环运行等待这些事件的回调。未完成的操作将保持挂起状态，直到事件循环的将来某个时刻。

上文展示了什么？展示了如何开始操作并在操作就绪后执行回调。异步框架建立在上文展示的两个功能（无阻塞套接字和事件循环）的基础上，可以在单个线程上运行并发操作。

我们在这里实现了“并发”，但是没有实现传统上所谓的“并行”。 也就是说，我们构建了一个很小的系统，该系统执行重叠的 I/O。它能够在其他飞机飞行时开始新的操作。 它实际上并没有利用多个内核并行执行计算。 但是然后，此系统是针对 I/O 约束的问题而不是 CPU 约束的问题而设计的。

因此，我们的事件循环在处理并发 I/O 上效率很高，因为它不会给每个连接分配线程资源。但是在继续之前，重要的是先纠正一个常见的误解：异步比多线程要快。通常并非如此——实际上，在Python中，在提供少量非常活跃的连接时，像我们这样的事件循环比多线程要慢一些。在没有全局解释器锁的运行时中，线程在这种工作负载下会表现得更好。 异步 I/O 最适合的应用是具有许多不频繁事件的慢速或睡眠连接的应用程序。


## 使用回调编程

使用目前构建的简短的异步框架，可以创建了爬虫程序了吗？ 即使是简单的 URL 提取程序也很难编写。

## 协程

## Python 生成器如何工作

## 使用生成器创建协程

## 使用 `yield from` 分解协程

## 协程协调

## 结论

现代程序越来越经常受 I/O 约束，而不是受 CPU 约束。对于这样的程序，Python 线程是个两头吃亏的选择：全局解释器锁阻止它们真实的并行计算，而抢占式切换使它们易于发生竞争。异步通常是正确的模式。但是随着基于回调的异步代码的增长，它往往会变得混乱不堪。协程是一个整洁的选择。它们自然地包含在子例程中，并具有健全的异常处理和堆栈跟踪功能。

如果我们斜视以使语句的收益模糊，那么协程看起来就像是执行传统阻塞I / O的线程。 我们甚至可以将协程与来自多线程编程的经典模式进行协调。 无需重新发明。 因此，与回调相比，协程对于使用多线程的程序员是一个诱人的习惯用法。

但是，当我们睁开眼睛，专注于语句的收益时，我们看到它们在协程让步并允许其他人运行时标记了点。 与线程不同，协程会显示我们的代码可以在何处中断和无法在何处中断。 格里夫·莱夫科维茨（Glyph Lefkowitz）在他的启发性文章“坚强” 14中写道：“线程使本地推理变得困难，本地推理可能是软件开发中最重要的事情。” 但是，显式屈服可以“通过检查例程本身而不是整个系统来了解例程的行为（从而，正确性）”。

本章是在Python和异步技术的复兴中撰写的。 您刚刚学会了设计的基于生成器的协程，已于2014年3月在Python 3.4的“异步”模块中发布。2015年9月，Python 3.5随语言本身内置的协程一起发布。 这些本机协程以新语法“ async def”声明，而不是“ yield from”，而是使用新的“ await”关键字委派给协程或等待Future。

尽管取得了这些进步，但核心思想仍然存在。 Python的新本机协程在语法上将与生成器不同，但工作方式非常相似。 实际上，他们将在Python解释器中共享一个实现。 任务，未来和事件循环将继续在异步中发挥作用。

既然您知道了异步协程的工作原理，就可以在很大程度上忘记细节。 机器被塞在一个精巧的接口后面。 但是，您掌握了基础知识后，便可以在现代异步环境中正确有效地进行编码。

